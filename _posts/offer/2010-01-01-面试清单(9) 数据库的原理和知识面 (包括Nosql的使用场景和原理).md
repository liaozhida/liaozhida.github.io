---
layout:     post
title:      "面试清单(9)"
subtitle: ""
date:       2010-10-23 12:00:00
author:     "zhidaliao"
header-img: "img/post-bg-road.jpg"
tags:
    - zчастный
---
面试清单(9) 数据库的原理和知识面 (包括Nosql的使用场景和原理).md


## mongo

###### Mongo的优化 监控

工具： mongostats mongotop	Http Console
命令： db.currentOp() db.serverStatus() 	db.stats()
profiler

优化：
索引 限定返回数目	读写分离
Capped Collections： 没有索引、不需要维护 根据顺序返回  固定大小

查看博客的归纳

###### Mongo 

token的保存 / 活动数据 、 


## redis


###### redis实现分布式锁

- 实现Lock接口
- 可重入机制  与jdk里面的ReentrantLock功能类似。重入次数靠hincrby  （为哈希表 key 中的域 field 的值加上增量 increment 。）


- 判断lock键是否存在，不存在直接调用hset存储当前线程信息并且设置过期时间,返回nil，告诉客户端直接获取到锁。
- 判断lock键是否存在，存在则将重入次数加1，并重新设置过期时间，返回nil，告诉客户端直接获取到锁。
- 被其它线程已经锁定，返回锁有效期的剩余时间，告诉客户端需要等待。



###### Redis订阅发布

发布订阅模式


###### redis 的用途  遇到的问题  解决

信息的展示 、 分布式全局锁 、 使用 redis 去实现显示锁 、 频繁提交 、 消息队列 、 elk / 短信发送 、 redis-session / 

hash类型 节约内存

Java并发插入 ？？？


###### redis 发布订阅


###### redis的面试题

[redis的面试题](http://www.cnblogs.com/plf112233/p/redis.html)
[Redis 核心功能解析](https://yyqian.com/post/1465440721000/)
[关于Redis的常识](http://blog.jobbole.com/44476/)  这个要细看
[MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据](http://chown-jane-y.coding.me/2017/03/26/Redis%E9%9C%80%E8%A6%81%E4%BA%86%E8%A7%A3%E7%9A%84%E5%87%A0%E4%B8%AA%E7%9F%A5%E8%AF%86%E7%82%B9/)
[redis的面试题](https://www.bbsmax.com/A/6pdDXvXdw3/)

如何保证redis中的数据都是热点数据: 使用LRU策略

事务命令？ watch实现

multi watch exec discard

watch用于事务开始前，监视的建是否被修改，是就不执行

在每个代表数据库的 redis.h/redisDb 结构类型中， 都保存了一个 watched_keys 字典， 字典的键是这个数据库被监视的键， 而字典的值则是一个链表， 链表中保存了所有监视这个键的客户端。

WATCH 命令的作用， 就是将当前客户端和要监视的键在 watched_keys 中进行关联。

在任何对数据库键空间（key space）进行修改的命令成功执行之后 （比如 FLUSHDB 、 SET 、 DEL 、 LPUSH 、 SADD 、 ZREM ，诸如此类）， multi.c/touchWatchedKey 函数都会被调用 —— 它检查数据库的 watched_keys 字典， 看是否有客户端在监视已经被命令修改的键， 如果有的话， 程序将所有监视这个/这些被修改键的客户端的 REDIS_DIRTY_CAS 选项打开：

当客户端发送 EXEC 命令、触发事务执行时， 服务器会对客户端的状态进行检查：


事务写入发生中断？

- 当使用Append-Only模式时，Redis会通过调用系统函数write将该事务内的所有写操作在本次调用中全部写入磁盘。
- 然而如果在写入的过程中出现系统崩溃，如电源故障导致的宕机，那么此时也许只有部分数据被写入到磁盘，而另外一部分数据却已经丢失。
- Redis服务器会在重新启动时执行一系列必要的一致性检测，一旦发现类似问题，就会立即退出并给出相应的错误提示。
- 此时，我们就要充分利用Redis工具包中提供的redis-check-aof工具，该工具可以帮助我们定位到数据不一致的错误，并将已经写入的部分数据进行回滚。
- 修复之后我们就可以再次重新启动Redis服务器了。


redis持久化的几种方式：

- AppendOnlyFile
- 快照（snapshots）
- 


AOF:
同步命令的三个阶段： 命令传播（将信息发送到AOF程序中）	缓存追加（将信息转换成网络通讯协议，保存在AOF缓存中）	`写入`和`保存`（将信息写入AOF文件末尾，当条件满足将会调用 fsync保存到磁盘中）

几种保存模式: 1 不保存 	2、每秒执行一次 保存操作由子线程负责，写入一样会阻塞 	3、每次执行命令保存一次 同2； 

如何还原数据： 创建一个伪客户端，读取命令执行操作。

什么是重写：读取原来的AOF，重新处理写入一份新的AOF文件，简化命令，关注结果不关注过程

介绍一下AOF后台重写：
Redis 不希望 AOF 重写造成服务器无法处理请求， 所以 Redis 决定将 AOF 重写程序放到（后台）子进程里执行， 这样处理的最大好处是：
	子进程进行 AOF 重写期间，主进程可以继续处理命令请求。
	子进程带有主进程的数据副本，使用子进程而不是线程，可以在避免锁的情况下，保证数据的安全性。

不过， 使用子进程也有一个问题需要解决： 因为子进程在进行 AOF 重写期间， 主进程还需要继续处理命令， 而新的命令可能对现有的数据进行修改， 这会让当前数据库的数据和重写后的 AOF 文件中的数据不一致。
为了解决这个问题， Redis 增加了一个 `AOF 重写缓存`， 这个缓存在 fork 出子进程之后开始启用， Redis 主进程在接到新的写命令之后， 除了会将这个写命令的协议内容追加到现有的 AOF 文件之外， 还会追加到这个缓存中：

**过期：**

rename之后失效时间不会改变

server.maxmemory：默认为0，没有指定最大缓存，如果有新的数据添加，Redis数据超过设置的最大内存会崩溃


说一下复制或者读写分离：

Redis 可以跟 MySQL 一样，实现 master/slave 结构，master 负责写操作，slave 负责读操作。

单个 Redis 服务大概能处理 100 commands/second，当数据量到几百万的时候，set/zset 操作可能需要几秒才能完成。

配置 Replication 的时候，在 Master 端我们要配置 dir 和 dbfilename 参数，确保 BGSAVE 可以写到本地磁盘上。在 Slave 端，我们要配置 slaveof host port。

我们一般让 Master 只使用 50-65% 的总内存，来确保 BGSAVE 的执行。Slave 在启动的时候先从本地的 snapshot/AOF 中恢复数据，然后连接到 master 来执行复制操作。


介绍管道：pipeline

将数据批量处理，减少网络开销


一个简单的分布式锁：

加锁：构造一个锁 LOCK（这里是 lock:user:yyqian），并且生成一个 UUID
用 SETNX LOCK UUID 来设定一个键

释放：先 WATCH LOCK
获取 LOCK 的值，检查是否跟上面返回的 UUID 相同，如果不同说明出错，UNWATCH 然后返回
依次执行 MULTI, DEL LOCK, EXEC

节点间如何争夺 master:
SetNx， 仅当key不存在时才Set。可以用来选举Master或做分布式锁：所有Client不断尝试使用SetNx master myName抢注Master，成功的那位不断使用Expire刷新它的过期时间。如果Master倒掉了key就会失效，剩下的节点又会发生新一轮抢夺。


几种数据结构: string hash set list sorted set

redis是单线程架构 纯ANSI C编写

过期删除策略
遍历所有数据消耗也大，Redis使用了一种相对务实的做法： 当client主动访问key会先对key进行超时判断，过时的key会立刻删除。 如果clien永远都不再get那条key呢？ 它会在Master的后台，每秒10次的执行如下操作： 随机选取100个key校验是否过期，如果有25个以上的key过期了，立刻额外随机选取下100个key(不计算在10次之内)。可见，如果过期的key不多，它最多每秒回收200条左右，如果有超过25%的key过期了，它就会做得更多，但只要key不被主动get，它占用的内存什么时候最终被清理掉只有天知道。

性能调优：

1.MSet/LPush/ZAdd等都支持一次输入多个Key。
2.PipeLining模式 可以一次输入多个指令。
3.更快的是Lua Script模式，还可以包含逻辑，直接在服务端又get又set的，见2.8 Lua Script。


内存：
- 一定要设置最大内存，否则物理内存用爆了就会大量使用Swap，写RDB文件时的速度慢得你想死。
- 多留一倍内存是最安全的。
	- 重写AOF文件和RDB文件的进程(即使不做持久化，复制到Slave的时候也要写RDB)会fork出一条新进程来，
	- 采用了操作系统的Copy-On-Write策略(子进程与父进程共享Page。如果父进程的Page-每页4K有修改，父进程自己创建那个Page的副本，不会影响到子进程，父爱如山)。
	- 留意Console打出来的报告，如”RDB: 1215 MB of memory used by copy-on-write”。在系统极度繁忙时，如果父进程的所有Page在子进程写RDB过程中都被修改过了，就需要两倍内存。

高可用性
高可用性关乎系统出错时到底会丢失多少数据，多久不能服务。要综合考虑
持久化
Master-Slave复制
Fail-Over配置
具体Crash情形：比如Master死了，但Slave没死。或者只是Redis死了，操作系统没死等等。


## Mysql

###### 数据库隔离级别

###### mysql的索引维护

###### MySQL常用SQL语句优化

###### BTree相关的操作

###### 存储过程


###### 数据库优化

查询重写

查询数据 非事务的存储引擎

MariaDB默认的存储引擎是Aria

myIsam和innodb 区别


MyISAM在所有MySQL配置里被支持，它是默认的存储引擎，从MySQL 5.5之后的版本中，默认的搜索引擎变更为InnoDB。


- MyISAM不支持事务，它提供高速存储和检索，以及全文搜索能力
- 如果执行大量的SELECT，MyISAM是更好的选择
- MyISAM只要简单的读出保存好的行数，注意的是，当`count(*)`语句包含   where条件时，两种表的操作是一样的



- InnoDB提供事务支持事务，外部键（foreign key）等高级数据库功能
- 执行大量的 UPDATE，出于性能方面的考虑，应该使用InnoDB表
- DELETE   FROM table时，InnoDB不会重新建立表，而是一行一行的删除。
- InnoDB 中不保存表的具体行数，InnoDB要扫描一遍整个表来计算有多少行
- 大尺寸的数据集趋向于选择InnoDB方式，因为其支持事务处理和故障恢复。数据库的大小决定了故障恢复的时间长短，InnoDB可以利用事务日志进行数据恢复，这会比较快。



InnoDB表的行锁也不是绝对的，如果在执行一个SQL语句时MySQL不能确定要扫描的范围，InnoDB表同样会锁全表， 例如update table set num=1 where name like “%aaa%






###### index Method hash btree的选择

Hash 索引结构的特殊性，其检索效率非常高，索引的检索可以一次定位，不像B-Tree 索引需要从根节点到枝节点，最后才能访问到页节点这样多次的IO访问，所以 Hash 索引的查询效率要远高于 B-Tree 索引。

- Hash 索引仅仅能满足”=”,”IN”和”<=>”查询，不能使用范围查询。
- Hash 索引无法被用来避免数据的排序操作。
- Hash 索引不能利用部分索引键查询。
- Hash 索引在任何时候都不能避免表扫描。
- Hash 索引遇到大量Hash值相等的情况后性能并不一定就会比B-Tree索引高。



[MySQL索引的Index method中btree和hash的区别](http://blog.csdn.net/qdujunjie/article/details/43794153)


###### 建索引的几大原则：

- 最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配，比如a = 1 and b = 2 and c > 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c- 索引则都可以用到，a,b,d的顺序可以任意调整。
- =和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式
- 尽量选择区分度高的列作为索引,区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条记录
- 索引列不能参与计算，保持列“干净”，比如from_unixtime(create_time) = ’2014-05-29’就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大。所以语句应该写成create_time = unix_timestamp(’2014-05-29’);
- 尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可



###### 联合索引的最左前缀匹配原则

```
KEY `a_b_c_index` (`username`,`password`,`usertype`)
```

- 当存在username时会使用索引查询：
- 当没有username时，不会使用索引查询：
- 当有username，但顺序乱序时也可以使用索引：
- 最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配，比如a = 1 and b = 2 and c > 3 and d = 4 如果建立`(a,b,c,d)`顺序的索引，d是用不到索引的，如果建立`(a,b,d,c)`的索引则都可以用到，a,b,d的顺序可以任意调整。
- =和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式


###### 慢查询优化基本步骤

- 先运行看看是否真的很慢，注意设置SQL_NO_CACHE
- where条件单表查，锁定最小返回记录表。这句话的意思是把查询语句的where都应用到表中返回的记录数最小的表开始查起，单表每个字段分别查询，看哪个字段的区分度最高
- explain查看执行计划，是否与1预期一致（从锁定记录较少的表开始查询）
- order by limit 形式的sql语句让排序的表优先查 
- 了解业务方使用场景  
- 加索引时参照建索引的几大原则 
- 观察结果，不符合预期继续从头分析


###### 大数据量的优化

- 分表分库
- 数据分片
- 索引。
- 存储过程
- 优化查询
- 减少不必要的查询字段
- 切分查询
- 分解关联查询

mysql解析查询，创建解析树，优化（重写查询，决定表的顺序，选择合适的索引）

[联合索引的最左前缀匹配原则](http://www.jianshu.com/p/b7911e0394b0)



#### 数据库

大数据量的优化

执行计划

查询优化  主索引 从索引

jdbc编程

确认索引正确运行



###### jdbc编程

加载数据库驱动并建立到数据库的连接。
通过Connection 对象的 createStatement()方法可以创建一个Statement对象，Statement 类的主要是用于执行静态 SQL 语句并返回它所生成结果的对象
调用Statement对象的相关方法执行相对应的 SQL 语句
处理结果。
从数据库断开连接释放资源。


###### [JDBC为什么要使用PreparedStatement而不是Statement](http://www.importnew.com/5006.html)

Statement 用于通用查询， PreparedStatement 用于执行参数化查询，而 CallableStatement则是用于存储过程

- 数据库系统会对sql语句进行预编译处理（如果JDBC驱动支持的话），预处理语句将被预先编译好，这条预编译的sql查询语句能在将来的查询中重用，这样一来，它比Statement对象生成的查询速度更快。
- PreparedStatement可以写动态参数化的查询 为了获得性能上的优势，应该使用参数化sql查询而不是字符串追加的方式
- 不会将参数的内容视为SQL指令的一部分来处理，而是在数据库完成SQL指令的编译后，才套用参数运行，因此就算参数中含有破坏性的指令，也不会被数据库所运行。

1. 为了防止SQL注入攻击，PreparedStatement不允许一个占位符（？）有多个值，在执行有**IN**子句查询的时候这个问题变得棘手起来。下面这个SQL查询使用PreparedStatement就不会返回任何结果


###### explain

[数据库调优教程（四）Explain性能分析命令](http://blog.csdn.net/hzy38324/article/details/44921299)
[MySQL存储引擎InnoDB与Myisam的六大区别](https://my.oschina.net/junn/blog/183341)
[MySQL索引原理及慢查询优化](https://tech.meituan.com/mysql-index.html)

######  Mysql / Postgres

选型是 Postgres ，jsonb的格式， 不方便。  阿里云mysql，转用，大家比较熟悉

MySQL 的事务隔离级别 repeatable read 并不能阻止常见的并发更新, 得加锁才可以, 但悲观锁会影响性能, 手动实现乐观锁又复杂. 而 Pg 的列里有隐藏的乐观锁 version 字段, 默认的 repeatable read 级别就能保证并发更新的正确性, 并且又有乐观锁的性能.


###### 数据库的索引引擎

myIsam

innoDb

为什么推荐InnoDB引擎使用自增主键？


###### 数据表的优化


- 重写查询 
	- 减少不必要的查询字段
	- 切分查询
	- 分解关联查询


- 优化查询表顺序
- 建立合适的索引

###### Mysql索引

[Mysql的主键争用问题如何解决](http://www.ywnds.com/?p=8735)