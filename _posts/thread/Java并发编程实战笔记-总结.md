---
layout:     post
title:      "Java并发编程实战笔记-总结"
date:       2016-01-29 12:00:00
author:     "zhidaliao"
header-img: "img/post-bg-2015.jpg"
tags:
    - 并发编程
---

> This document is not completed and will be updated anytime.
> Java并发编程实战这本书用到的类库都比较旧，需要及时更新
> 增加对线程安全类的源码研究


1. JAVA 悲观锁与乐观锁

我们都知道，cpu是时分复用的，也就是把cpu的时间片，分配给不同的thread/process轮流执行，时间片与时间片之间，需要进行cpu切换，也就是会发生进程的切换。切换涉及到清空寄存器，缓存数据。然后重新加载新的thread所需数据。当一个线程被挂起时，加入到阻塞队列，在一定的时间或条件下，在通过notify()，notifyAll()唤醒回来。在某个资源不可用的时候，就将cpu让出，把当前等待线程切换为阻塞状态。等到资源(比如一个共享数据）可用了，那么就将线程唤醒，让他进入runnable状态等待cpu调度。这就是典型的悲观锁的实现。独占锁是一种悲观锁，synchronized就是一种独占锁，它假设最坏的情况，并且只有在确保其它线程不会造成干扰的情况下执行，会导致其它所有需要锁的线程挂起，等待持有锁的线程释放锁。

但是，由于在进程挂起和恢复执行过程中存在着很大的开销。当一个线程正在等待锁时，它不能做任何事，所以悲观锁有很大的缺点。举个例子，如果一个线程需要某个资源，但是这个资源的占用时间很短，当线程第一次抢占这个资源时，可能这个资源被占用，如果此时挂起这个线程，可能立刻就发现资源可用，然后又需要花费很长的时间重新抢占锁，时间代价就会非常的高。

所以就有了乐观锁的概念，他的核心思路就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。在上面的例子中，某个线程可以不让出cpu,而是一直while循环，如果失败就重试，直到成功为止。所以，当数据争用不严重时，乐观锁效果更好。比如CAS就是一种乐观锁思想的应用。


编写线程安全代码的核心在于:对`共享` `可变的`状态访问操作进行管理，同时注意迭代器模式中的并发修改异常

线程安全类的定义: 多个线程访问某个类时,类始终表现出正确的行为

方法： 
- 不共享（线程封闭）
- 可变的 (final)
- 多个线程访问： 同步、内存可见性

2. 数据库 悲观锁与乐观锁

悲观锁：储存层或服务层的 行锁表锁进行 强制独占
乐观锁：MVVC，隐藏的两列，保存更新时间 和 删除时间 ， 或者自增的版本号 ，事务读取提交的时候判断是否和当初一致


List  | Vector/ Collections.synchronizedList | CopyOnWriteArrayList 
HashMap | HashTable / Collections.synchronizedMap | ConcurrentHashMap
Set | Collections.synchronizedSet | CopyOnWriteArraySet
queue | concurrentLinkQueue 


#### 内存栅栏？

- 对主存的一次访问一般花费硬件的数百次时钟周期。为了减少这种操作，CPU通过使用Cache来达到高效获取数据的目的。
- 然后Cache为了提高性能（命中率），会对指令进行重排序。
- 当重排序对最终的结果没有影响的时候，这种优化是有益的。但是当多线程共享数据时，重排序将导致错误的结果。
- 所以为了在共享变量的情况下依然可以使用指令重排序，产生了内存栅栏来保证程序的正确性。

内存栅栏(Memory Barriers)，是让一个CPU处理单元中的内存状态对其它处理单元可见的一项技术。

是一类同步屏障指令，内存屏障是底层原语 ，是CPU或编译器在对内存随机访问的操作中的一个同步点，使得此点之前的所有读写操作都执行后，才可以开始执行此点之后的操作。

语义上，内存屏障之前的所有写**操作**，都要写回主内存； 内存屏障之后的读操作，都可以获得同步屏障之前的写操作的结果。因此，对于敏感的程序块，写操作之后、读操作之前可以插入内存屏障。

###### Java中内存栅栏的使用

Java内存模型中volatile变量在写操作之后会插入一个store屏障，在读操作之前会插入一个load屏障。一个类的final字段会在初始化后插入一个store屏障，来确保final字段在构造函数初始化完成并可被使用时可见。

内存可见性问题，主要是高速缓存与内存的一致性问题。一个处理器上的线程修改了某数据，而在另一处理器上的线程可能仍然使用着该数据在专用cache中的老值，这就是可见性出了问题。解决办法是令该数据为 volatile 属性，或者读该数据之前执行内存屏障。



```
CPU核
|
V
寄存器
|
V
执行单元 -> Load/Store缓冲区->L1 Cache --->L3 Cache-->内存控制器-->主存
| |
+-> Write Combine缓冲区->L2 Cache ---+
```

代码顺序并不是真正的执行顺序，只要有空间提高性能，CPU和编译器可以进行各种优化。`缓存`和主存的读取会利用load, store和write-combining`缓冲区`来缓冲和重排。这些缓冲区是查找速度很快的关联队列，当一个后来发生的load需要读取上一个store的值，而该值还没有到达缓存，查找是必需的

从上图可以看出执行单元可以利用 **本地寄存器和缓冲区** 来管理 与 **缓存子系统**的交互。

一旦内存数据被推送到缓存，就会有消息协议来确保所有的缓存会对所有的共享数据同步并保持一致。这个使内存数据对CPU核可见的技术被称为内存屏障或内存栅栏。

内存栅栏提供了两个功能
- 确保从另一个CPU来看,栅栏的两边的所有指令都是正确的 程序顺序，保持**程序顺序**的外部可见性；
- 实现内存数据可见性，确保主存数据会同步到CPU缓存子系统。


大多数处理器提供了内存屏障指令:
- 完全内存屏障（full memory barrier）保障了早于屏障的内存读写操作的结果提交到内存之后，再执行晚于屏障的读写操作。
- 内存读屏障（read memory barrier）仅确保了内存读操作；
- 内存写屏障(write memory barrier)仅保证了内存写操作。

[内存屏障](http://ifeve.com/memory-barriers-or-fences/)